{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import projectLib as lib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set highest rating\n",
    "K = 5\n",
    "F = 3\n",
    "eps=0.1\n",
    "\n",
    "def softmax(x):\n",
    "    # Numerically stable softmax function\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "def ratingsPerMovie(training):\n",
    "    movies = [x[0] for x in training]\n",
    "    u_movies = np.unique(movies).tolist()\n",
    "    return np.array([[i, movie, len([x for x in training if x[0] == movie])] for i, movie in enumerate(u_movies)])\n",
    "\n",
    "def getV(ratingsForUser):\n",
    "    # ratingsForUser is obtained from the ratings for user library\n",
    "    # you should return a binary matrix ret of size m x K, where m is the number of movies\n",
    "    #   that the user has seen. ret[i][k] = 1 if the user\n",
    "    #   has rated movie ratingsForUser[i, 0] with k stars\n",
    "    #   otherwise it is 0\n",
    "    ret = np.zeros((len(ratingsForUser), K))\n",
    "    for i in range(len(ratingsForUser)):\n",
    "        ret[i, ratingsForUser[i, 1]-1] = 1.0\n",
    "    return ret\n",
    "\n",
    "def getInitialWeights(m, F, K):\n",
    "    # m is the number of visible units\n",
    "    # F is the number of hidden units\n",
    "    # K is the highest rating (fixed to 5 here)\n",
    "    return np.random.normal(0, 0.1, (m, F, K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = lib.getTrainingData()\n",
    "ratingsForUser1 = lib.getRatingsForUser(1, training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ratingsPerMovie(training)\n",
    "v = getV(ratingsForUser1)\n",
    "# v.shape\n",
    "w = getInitialWeights(v.shape[0],F,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trStats = lib.getUsefulStats(training)\n",
    "W = getInitialWeights(trStats[\"n_movies\"], F, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig(x):\n",
    "    ### TO IMPLEMENT ###\n",
    "    # x is a real vector of size n\n",
    "    # ret should be a vector of size n where ret_i = sigmoid(x_i)\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def visibleToHiddenVec(v, w):\n",
    "    ### TO IMPLEMENT ###\n",
    "    # v is a matrix of size m x 5. Each row is a binary vector representing a rating\n",
    "    #    OR a probability distribution over the rating\n",
    "    # w is a list of matrices of size m x F x 5\n",
    "    # ret should be a vector of size F\n",
    "    m,f,K=w.shape\n",
    "    output=list()\n",
    "    for i in range(f):\n",
    "        summ=0\n",
    "        for k in range(K):\n",
    "            for j in range(m):\n",
    "                summ+=v[j,k]*w[j,i,k]\n",
    "        output.append(summ)\n",
    "    return sig(np.array(output))\n",
    "    \n",
    "\n",
    "def hiddenToVisible(h, w):\n",
    "    ### TO IMPLEMENT ###\n",
    "    # h is a binary vector of size F\n",
    "    # w is an array of size m x F x 5\n",
    "    # ret should be a matrix of size m x 5, where m\n",
    "    #   is the number of movies the user has seen.\n",
    "    #   Remember that we do not reconstruct movies that the user\n",
    "    #   has not rated! (where reconstructing means getting a distribution\n",
    "    #   over possible ratings).\n",
    "    #   We only do so when we predict the rating a user would have given to a movie.\n",
    "#     print(w.shape)\n",
    "    output=w[:,0,:]*h[0]\n",
    "    m,f,k=w.shape\n",
    "    for i in range(1,f):\n",
    "        output+=w[:,i,:]*h[i]\n",
    "    return sig(output)\n",
    "\n",
    "def probProduct(v, p):\n",
    "    # v is a matrix of size m x 5\n",
    "    # p is a vector of size F, activation of the hidden units\n",
    "    # returns the gradient for visible input v and hidden activations p\n",
    "    ret = np.zeros((v.shape[0], p.size, v.shape[1]))\n",
    "    for i in range(v.shape[0]):\n",
    "        for j in range(p.size):\n",
    "            for k in range(v.shape[1]):\n",
    "                ret[i, j, k] = v[i, k] * p[j]\n",
    "    return ret\n",
    "\n",
    "def sample(p):\n",
    "    # p is a vector of real numbers between 0 and 1\n",
    "    # ret is a vector of same size as p, where ret_i = Ber(p_i)\n",
    "    # In other word we sample from a Bernouilli distribution with\n",
    "    # parameter p_i to obtain ret_i\n",
    "    samples = np.random.random(p.size)\n",
    "    return np.array(samples <= p, dtype=int)\n",
    "\n",
    "def getPredictedDistribution(v, w, wq):\n",
    "    ### TO IMPLEMENT ###\n",
    "    # This function returns a distribution over the ratings for movie q, if user data is v\n",
    "    # v is the dataset of the user we are predicting the movie for\n",
    "    #   It is a m x 5 matrix, where m is the number of movies in the\n",
    "    #   dataset of this user.\n",
    "    # w is the weights array for the current user, of size m x F x 5\n",
    "    # wq is the weight matrix of size F x 5 for movie q\n",
    "    #   If W is the whole weights array, then wq = W[q, :, :]\n",
    "    # You will need to perform the same steps done in the learning/unlearning:\n",
    "    #   - Propagate the user input to the hidden units\n",
    "    #   - Sample the state of the hidden units\n",
    "    #   - Backpropagate these hidden states to obtain\n",
    "    #       the distribution over the movie whose associated weights are wq\n",
    "    # ret is a vector of size 5\n",
    "    m,f,K=w.shape\n",
    "    p_learn = visibleToHiddenVec(v,w)\n",
    "    PG = probProduct(v, p_learn)\n",
    "    hidden_activations = sample(p_learn)\n",
    "#     print(hidden_activations)\n",
    "    v_negative = hiddenToVisible(hidden_activations, wq.reshape(1,wq.shape[0],wq.shape[1]))\n",
    "#     p_unlearn = visibleToHiddenVec(v_negative, w)\n",
    "#     NG = probProduct(v_negative, p_unlearn)\n",
    "# #     print(eps*(PG-NG))\n",
    "# #     print (w.shape)\n",
    "#     w += eps*(PG-NG)\n",
    "    return v_negative.reshape(5)\n",
    "\n",
    "def predictRatingMax(ratingDistribution):\n",
    "    ### TO IMPLEMENT ###\n",
    "    # ratingDistribution is a probability distribution over possible ratings\n",
    "    #   It is obtained from the getPredictedDistribution function\n",
    "    # This function is one of three you are to implement\n",
    "    # that returns a rating from the distribution\n",
    "    # We decide here that the predicted rating will be the one with the highest probability\n",
    "    result = np.where(ratingDistribution == np.amax(ratingDistribution))[0].item()\n",
    "    return result+1\n",
    "\n",
    "def predictRatingMean(ratingDistribution):\n",
    "    ### TO IMPLEMENT ###\n",
    "    # ratingDistribution is a probability distribution over possible ratings\n",
    "    #   It is obtained from the getPredictedDistribution function\n",
    "    # This function is one of three you are to implement\n",
    "    # that returns a rating from the distribution\n",
    "    # We decide here that the predicted rating will be the expectation over ratingDistribution\n",
    "    normalized = ratingDistribution/sum(ratingDistribution)\n",
    "    result = 0 \n",
    "    for k in range(ratingDistribution.shape[0]):\n",
    "        result += normalized[k]*(k+1)\n",
    "    return result\n",
    "\n",
    "def predictRatingExp(ratingDistribution):\n",
    "    ### TO IMPLEMENT ###\n",
    "    # ratingDistribution is a probability distribution over possible ratings\n",
    "    #   It is obtained from the getPredictedDistribution function\n",
    "    # This function is one of three you are to implement\n",
    "    # that returns a rating from the distribution\n",
    "    # We decide here that the predicted rating will be the expectation over\n",
    "    # the softmax applied to ratingDistribution\n",
    "    softmax = np.exp(ratingDistribution)/sum(np.exp(ratingDistribution))\n",
    "#     print(softmax)\n",
    "    result = 0 \n",
    "    for k in range(len(ratingDistribution)):\n",
    "        result += softmax[k]*(k+1)\n",
    "#         print (result)\n",
    "    return result\n",
    "\n",
    "def predictMovieForUser(q, user, W, training, predictType=\"exp\"):\n",
    "    # movie is movie idx\n",
    "    # user is user ID\n",
    "    # type can be \"max\" or \"exp\"\n",
    "    ratingsForUser = lib.getRatingsForUser(user, training)\n",
    "    v = getV(ratingsForUser)\n",
    "#     print(np.where(ratingsForUser[:,0]==q))\n",
    "    ratingDistribution = getPredictedDistribution(v, W[ratingsForUser[:, 0], :, :], W[q, :, :])#[np.where(ratingsForUser[:,0]==q)[0][0]]\n",
    "    if predictType == \"max\":\n",
    "        return predictRatingMax(ratingDistribution)\n",
    "    elif predictType == \"mean\":\n",
    "        return predictRatingMean(ratingDistribution)\n",
    "    else:\n",
    "        return predictRatingExp(ratingDistribution)\n",
    "\n",
    "def predict(movies, users, W, training, predictType=\"exp\"):\n",
    "    # given a list of movies and users, predict the rating for each (movie, user) pair\n",
    "    # used to compute RMSE\n",
    "    return [predictMovieForUser(movie, user, W, training, predictType=predictType) for (movie, user) in zip(movies, users)]\n",
    "\n",
    "def predictForUser(user, W, training, predictType=\"exp\"):\n",
    "    ### TO IMPLEMENT\n",
    "    # given a user ID, predicts all movie ratings for the user\n",
    "    \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49640239 0.48419042 0.52191786 0.44509767 0.44596078]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.9722750791189103"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = np.random.choice(ratingsForUser1[:, 0])\n",
    "index = np.where(ratingsForUser1[:, 0]==q)[0].item()\n",
    "ratingdist1 = getPredictedDistribution(v, W[ratingsForUser1[:, 0], :, :], W[q, :, :])#[index]\n",
    "print(ratingdist1)\n",
    "predictRatingExp(ratingdist1)\n",
    "# Problem remains - we need the index to know which movie to take the values from in the \n",
    "# getPredictedDistribution function. Need to check with TA and clarify that part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictForUser(user, W, training, predictType=\"exp\"):\n",
    "    ### TO IMPLEMENT\n",
    "    # given a user ID, predicts all movie ratings for the user\n",
    "    ratingsForUser = lib.getRatingsForUser(user, training)\n",
    "    v = getV(ratingsForUser)\n",
    "    ratings = []\n",
    "    for i in range(np.shape(ratingsForUser)[0]):\n",
    "        ratingDistribution = getPredictedDistribution(v, W[ratingsForUser[:, 0], :, :], W[ratingsForUser[:,0][i], :, :])[i]\n",
    "#         print(ratingDistribution)\n",
    "#     return v\n",
    "#     ratingDistribution = getPredictedDistribution(v, W[ratingsForUser[:, 0], :, :], )\n",
    "        if predictType == \"max\":\n",
    "            ratings.append(predictRatingMax(ratingDistribution))\n",
    "        elif predictType == \"mean\":\n",
    "            ratings.append(predictRatingMean(ratingDistribution))\n",
    "        else:\n",
    "#             print (predictRatingExp(ratingDistribution))\n",
    "            ratings.append(predictRatingExp(ratingDistribution))\n",
    "    return ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### EPOCH 1 ###\n",
      "Training loss = 1.170921\n",
      "Validation loss = 1.200595\n",
      "### EPOCH 2 ###\n",
      "Training loss = 1.199070\n",
      "Validation loss = 1.228177\n",
      "### EPOCH 3 ###\n",
      "Training loss = 1.196801\n",
      "Validation loss = 1.227071\n",
      "### EPOCH 4 ###\n",
      "Training loss = 1.189118\n",
      "Validation loss = 1.225244\n",
      "### EPOCH 5 ###\n",
      "Training loss = 1.186265\n",
      "Validation loss = 1.223309\n",
      "### EPOCH 6 ###\n",
      "Training loss = 1.185928\n",
      "Validation loss = 1.225180\n",
      "### EPOCH 7 ###\n",
      "Training loss = 1.184300\n",
      "Validation loss = 1.220642\n",
      "### EPOCH 8 ###\n",
      "Training loss = 1.186457\n",
      "Validation loss = 1.224596\n",
      "### EPOCH 9 ###\n",
      "Training loss = 1.187067\n",
      "Validation loss = 1.226733\n",
      "### EPOCH 10 ###\n",
      "Training loss = 1.186364\n",
      "Validation loss = 1.229250\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import rbm\n",
    "import projectLib as lib\n",
    "\n",
    "training = lib.getTrainingData()\n",
    "validation = lib.getValidationData()\n",
    "# You could also try with the chapter 4 data\n",
    "# training = lib.getChapter4Data()\n",
    "\n",
    "trStats = lib.getUsefulStats(training)\n",
    "vlStats = lib.getUsefulStats(validation)\n",
    "\n",
    "K = 5\n",
    "alpha = 0.9\n",
    "\n",
    "# SET PARAMETERS HERE!!!\n",
    "# number of hidden units\n",
    "F = 5\n",
    "epochs = 10\n",
    "gradientLearningRate = 0.0001\n",
    "_lambda = 0.3\n",
    "\n",
    "# Initialise all our arrays\n",
    "W = getInitialWeights(trStats[\"n_movies\"], F, K)\n",
    "posprods = np.zeros(W.shape)\n",
    "negprods = np.zeros(W.shape)\n",
    "m=np.zeros((97,F,5))\n",
    "train_loss = []\n",
    "validation_loss = []\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    # in each epoch, we'll visit all users in a random order\n",
    "    visitingOrder = np.array(trStats[\"u_users\"])\n",
    "    np.random.shuffle(visitingOrder)\n",
    "\n",
    "    for user in visitingOrder:\n",
    "        # get the ratings of that user\n",
    "        ratingsForUser = lib.getRatingsForUser(user, training)\n",
    "\n",
    "        # build the visible input\n",
    "        v = getV(ratingsForUser)\n",
    "\n",
    "        # get the weights associated to movies the user has seen\n",
    "        weightsForUser = W[ratingsForUser[:, 0], :, :]\n",
    "\n",
    "        ### LEARNING ###\n",
    "        # propagate visible input to hidden units\n",
    "        posHiddenProb = visibleToHiddenVec(v, weightsForUser)\n",
    "        # get positive gradient\n",
    "        # note that we only update the movies that this user has seen!\n",
    "        posprods[ratingsForUser[:, 0], :, :] += probProduct(v, posHiddenProb)\n",
    "\n",
    "        ### UNLEARNING ###\n",
    "        # sample from hidden distribution\n",
    "        sampledHidden = sample(posHiddenProb)\n",
    "        # propagate back to get \"negative data\"\n",
    "        negData = hiddenToVisible(sampledHidden, weightsForUser)\n",
    "        # propagate negative data to hidden units\n",
    "        negHiddenProb = visibleToHiddenVec(negData, weightsForUser)\n",
    "        # get negative gradient\n",
    "        # note that we only update the movies that this user has seen!\n",
    "        negprods[ratingsForUser[:, 0], :, :] += probProduct(negData, negHiddenProb)\n",
    "\n",
    "        # we average over the number of users in the batch (if we use mini-batch)\n",
    "        grad = (gradientLearningRate/epoch) * ((posprods - negprods)+2*_lambda*W)\n",
    "        \n",
    "        m = alpha*m+grad\n",
    "\n",
    "        W += m\n",
    "        \n",
    "\n",
    "    # Print the current RMSE for training and validation sets\n",
    "    # this allows you to control for overfitting e.g\n",
    "    # We predict over the training set\n",
    "    tr_r_hat = predict(trStats[\"movies\"], trStats[\"users\"], W, training)\n",
    "#     print (tr_r_hat)\n",
    "    trRMSE = lib.rmse(trStats[\"ratings\"], tr_r_hat)\n",
    "#     print (trRMSE)\n",
    "\n",
    "    # We predict over the validation set\n",
    "    vl_r_hat = predict(vlStats[\"movies\"], vlStats[\"users\"], W, training)\n",
    "#     vl_r_hat\n",
    "    vlRMSE = lib.rmse(vlStats[\"ratings\"], vl_r_hat)\n",
    "    \n",
    "    train_loss.append(trRMSE)\n",
    "    validation_loss.append(vlRMSE)\n",
    "\n",
    "    print (\"### EPOCH %d ###\" % epoch)\n",
    "    print (\"Training loss = %f\" % trRMSE)\n",
    "    print (\"Validation loss = %f\" % vlRMSE)\n",
    "\n",
    "### END ###\n",
    "# This part you can write on your own\n",
    "# you could plot the evolution of the training and validation RMSEs for example\n",
    "# predictedRatings = np.array([predictForUser(user, W, training) for user in trStats[\"u_users\"]])\n",
    "# np.savetxt(\"predictedRatings.txt\", predictedRatings)\n",
    "# fig1 = plt.figure()\n",
    "# ax1 = fig1.add_subplot(121)\n",
    "# ax1.plot(train_loss)\n",
    "# ax2 = fig1.add_subplot(122)\n",
    "# ax2.plot(validation_loss)\n",
    "\n",
    "plt.plot(train_loss)\n",
    "plt.plot(validation_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(posprods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vlStats[\"users\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(vl_r_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss)\n",
    "plt.plot(validation_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
