{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import projectLib as lib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set highest rating\n",
    "K = 5\n",
    "F = 3\n",
    "eps=0.1\n",
    "\n",
    "def softmax(x):\n",
    "    # Numerically stable softmax function\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "def ratingsPerMovie(training):\n",
    "    movies = [x[0] for x in training]\n",
    "    u_movies = np.unique(movies).tolist()\n",
    "    return np.array([[i, movie, len([x for x in training if x[0] == movie])] for i, movie in enumerate(u_movies)])\n",
    "\n",
    "def getV(ratingsForUser):\n",
    "    # ratingsForUser is obtained from the ratings for user library\n",
    "    # you should return a binary matrix ret of size m x K, where m is the number of movies\n",
    "    #   that the user has seen. ret[i][k] = 1 if the user\n",
    "    #   has rated movie ratingsForUser[i, 0] with k stars\n",
    "    #   otherwise it is 0\n",
    "    ret = np.zeros((len(ratingsForUser), K))\n",
    "    for i in range(len(ratingsForUser)):\n",
    "        ret[i, ratingsForUser[i, 1]-1] = 1.0\n",
    "    return ret\n",
    "\n",
    "def getInitialWeights(m, F, K):\n",
    "    # m is the number of visible units\n",
    "    # F is the number of hidden units\n",
    "    # K is the highest rating (fixed to 5 here)\n",
    "    return np.random.normal(0, 0.1, (m, F, K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training = lib.getTrainingData()\n",
    "ratingsForUser1 = lib.getRatingsForUser(1, training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ratingsPerMovie(training)\n",
    "v = getV(ratingsForUser1)\n",
    "# v.shape\n",
    "w = getInitialWeights(v.shape[0],F,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trStats = lib.getUsefulStats(training)\n",
    "W = getInitialWeights(trStats[\"n_movies\"], F, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig(x):\n",
    "    ### TO IMPLEMENT ###\n",
    "    # x is a real vector of size n\n",
    "    # ret should be a vector of size n where ret_i = sigmoid(x_i)\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def visibleToHiddenVec(v, w, hid_bias):\n",
    "    ### TO IMPLEMENT ###\n",
    "    # v is a matrix of size m x 5. Each row is a binary vector representing a rating\n",
    "    #    OR a probability distribution over the rating\n",
    "    # w is a list of matrices of size m x F x 5\n",
    "    # ret should be a vector of size F\n",
    "    m,f,K=w.shape\n",
    "    output=list()\n",
    "    for i in range(f):\n",
    "        summ=0\n",
    "        for k in range(K):\n",
    "            for j in range(m):\n",
    "                summ+=v[j,k]*w[j,i,k]\n",
    "        output.append(summ)\n",
    "\n",
    "    return sig(np.array(output)+hid_bias)\n",
    "    \n",
    "\n",
    "def hiddenToVisible(h, w, vis_bias):\n",
    "    ### TO IMPLEMENT ###\n",
    "    # h is a binary vector of size F\n",
    "    # w is an array of size m x F x 5\n",
    "    # ret should be a matrix of size m x 5, where m\n",
    "    #   is the number of movies the user has seen.\n",
    "    #   Remember that we do not reconstruct movies that the user\n",
    "    #   has not rated! (where reconstructing means getting a distribution\n",
    "    #   over possible ratings).\n",
    "    #   We only do so when we predict the rating a user would have given to a movie.\n",
    "#     print(w.shape)\n",
    "    output=w[:,0,:]*h[0]\n",
    "    m,f,k=w.shape\n",
    "    for i in range(1,f):\n",
    "        output+=w[:,i,:]*h[i]\n",
    "    return sig(output+vis_bias)\n",
    "\n",
    "def probProduct(v, p):\n",
    "    # v is a matrix of size m x 5\n",
    "    # p is a vector of size F, activation of the hidden units\n",
    "    # returns the gradient for visible input v and hidden activations p\n",
    "    ret = np.zeros((v.shape[0], p.size, v.shape[1]))\n",
    "    for i in range(v.shape[0]):\n",
    "        for j in range(p.size):\n",
    "            for k in range(v.shape[1]):\n",
    "                ret[i, j, k] = v[i, k] * p[j]\n",
    "    return ret\n",
    "\n",
    "def sample(p):\n",
    "    # p is a vector of real numbers between 0 and 1\n",
    "    # ret is a vector of same size as p, where ret_i = Ber(p_i)\n",
    "    # In other word we sample from a Bernouilli distribution with\n",
    "    # parameter p_i to obtain ret_i\n",
    "    samples = np.random.random(p.size)\n",
    "    return np.array(samples <= p, dtype=int)\n",
    "\n",
    "def getPredictedDistribution(v, w, wq,vis_bias,hid_bias):\n",
    "    ### TO IMPLEMENT ###\n",
    "    # This function returns a distribution over the ratings for movie q, if user data is v\n",
    "    # v is the dataset of the user we are predicting the movie for\n",
    "    #   It is a m x 5 matrix, where m is the number of movies in the\n",
    "    #   dataset of this user.\n",
    "    # w is the weights array for the current user, of size m x F x 5\n",
    "    # wq is the weight matrix of size F x 5 for movie q\n",
    "    #   If W is the whole weights array, then wq = W[q, :, :]\n",
    "    # You will need to perform the same steps done in the learning/unlearning:\n",
    "    #   - Propagate the user input to the hidden units\n",
    "    #   - Sample the state of the hidden units\n",
    "    #   - Backpropagate these hidden states to obtain\n",
    "    #       the distribution over the movie whose associated weights are wq\n",
    "    # ret is a vector of size 5\n",
    "    m,f,K=w.shape\n",
    "    p_learn = visibleToHiddenVec(v,w,hid_bias)\n",
    "    PG = probProduct(v, p_learn)\n",
    "    hidden_activations = sample(p_learn)\n",
    "    v_negative = hiddenToVisible(hidden_activations, wq.reshape(1,wq.shape[0],wq.shape[1]),vis_bias)\n",
    "\n",
    "    return v_negative.reshape(5)\n",
    "\n",
    "def predictRatingMax(ratingDistribution):\n",
    "    ### TO IMPLEMENT ###\n",
    "    # ratingDistribution is a probability distribution over possible ratings\n",
    "    #   It is obtained from the getPredictedDistribution function\n",
    "    # This function is one of three you are to implement\n",
    "    # that returns a rating from the distribution\n",
    "    # We decide here that the predicted rating will be the one with the highest probability\n",
    "    result = np.where(ratingDistribution == np.amax(ratingDistribution))[0].item()\n",
    "    return result+1\n",
    "\n",
    "def predictRatingMean(ratingDistribution):\n",
    "    ### TO IMPLEMENT ###\n",
    "    # ratingDistribution is a probability distribution over possible ratings\n",
    "    #   It is obtained from the getPredictedDistribution function\n",
    "    # This function is one of three you are to implement\n",
    "    # that returns a rating from the distribution\n",
    "    # We decide here that the predicted rating will be the expectation over ratingDistribution\n",
    "    normalized = ratingDistribution/sum(ratingDistribution)\n",
    "    result = 0 \n",
    "    for k in range(ratingDistribution.shape[0]):\n",
    "        result += normalized[k]*(k+1)\n",
    "    return result\n",
    "\n",
    "def predictRatingExp(ratingDistribution):\n",
    "    ### TO IMPLEMENT ###\n",
    "    # ratingDistribution is a probability distribution over possible ratings\n",
    "    #   It is obtained from the getPredictedDistribution function\n",
    "    # This function is one of three you are to implement\n",
    "    # that returns a rating from the distribution\n",
    "    # We decide here that the predicted rating will be the expectation over\n",
    "    # the softmax applied to ratingDistribution\n",
    "    softmax = np.exp(ratingDistribution)/sum(np.exp(ratingDistribution))\n",
    "#     print(softmax)\n",
    "    result = 0 \n",
    "    for k in range(len(ratingDistribution)):\n",
    "        result += softmax[k]*(k+1)\n",
    "#         print (result)\n",
    "    return result\n",
    "\n",
    "def predictMovieForUser(q, user, W, training,vis_bias,hid_bias, predictType=\"exp\"):\n",
    "    # movie is movie idx\n",
    "    # user is user ID\n",
    "    # type can be \"max\" or \"exp\"\n",
    "    ratingsForUser = lib.getRatingsForUser(user, training)\n",
    "    v = getV(ratingsForUser)\n",
    "#     print(np.where(ratingsForUser[:,0]==q))\n",
    "    ratingDistribution = getPredictedDistribution(v, W[ratingsForUser[:, 0], :, :], W[q, :, :],vis_bias[q],hid_bias)#[np.where(ratingsForUser[:,0]==q)[0][0]]\n",
    "    if predictType == \"max\":\n",
    "        return predictRatingMax(ratingDistribution)\n",
    "    elif predictType == \"mean\":\n",
    "        return predictRatingMean(ratingDistribution)\n",
    "    else:\n",
    "        return predictRatingExp(ratingDistribution)\n",
    "\n",
    "def predict(movies, users, W, training,vis_bias,hid_bias, predictType=\"exp\"):\n",
    "    # given a list of movies and users, predict the rating for each (movie, user) pair\n",
    "    # used to compute RMSE\n",
    "    return [predictMovieForUser(movie, user, W, training,vis_bias,hid_bias, predictType=predictType) for (movie, user) in zip(movies, users)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.52124675 0.55075269 0.52378671 0.53154691 0.53124646]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.000100451908751"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = np.random.choice(ratingsForUser1[:, 0])\n",
    "index = np.where(ratingsForUser1[:, 0]==q)[0].item()\n",
    "ratingdist1 = getPredictedDistribution(v, W[ratingsForUser1[:, 0], :, :], W[q, :, :])#[index]\n",
    "print(ratingdist1)\n",
    "predictRatingExp(ratingdist1)\n",
    "# Problem remains - we need the index to know which movie to take the values from in the \n",
    "# getPredictedDistribution function. Need to check with TA and clarify that part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictForUser(user, W, training, vis_bias, hid_bias,predictType=\"exp\"):\n",
    "    ### TO IMPLEMENT\n",
    "    # given a user ID, predicts all movie ratings for the user\n",
    "    ratingsForUser = lib.getRatingsForUser(user, training)\n",
    "    v = getV(ratingsForUser)\n",
    "    ratings = []\n",
    "    for i in range(np.shape(ratingsForUser)[0]):\n",
    "        ratingDistribution = getPredictedDistribution(v, W[ratingsForUser[:, 0], :, :], W[ratingsForUser[:,0][i], :, :],vis_bias[q,:],hid_bias)[i]\n",
    "#         print(ratingDistribution)\n",
    "#     return v\n",
    "#     ratingDistribution = getPredictedDistribution(v, W[ratingsForUser[:, 0], :, :], )\n",
    "        if predictType == \"max\":\n",
    "            ratings.append(predictRatingMax(ratingDistribution))\n",
    "        elif predictType == \"mean\":\n",
    "            ratings.append(predictRatingMean(ratingDistribution))\n",
    "        else:\n",
    "#             print (predictRatingExp(ratingDistribution))\n",
    "            ratings.append(predictRatingExp(ratingDistribution))\n",
    "    return ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vlStats['n_movies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### EPOCH 1 ###\n",
      "Training loss = 1.183419\n",
      "Validation loss = 1.213462\n",
      "### EPOCH 2 ###\n",
      "Training loss = 1.177858\n",
      "Validation loss = 1.211672\n",
      "### EPOCH 3 ###\n",
      "Training loss = 1.167257\n",
      "Validation loss = 1.212547\n",
      "### EPOCH 4 ###\n",
      "Training loss = 1.154022\n",
      "Validation loss = 1.208255\n",
      "### EPOCH 5 ###\n",
      "Training loss = 1.143903\n",
      "Validation loss = 1.214237\n",
      "### EPOCH 6 ###\n",
      "Training loss = 1.134182\n",
      "Validation loss = 1.208449\n",
      "### EPOCH 7 ###\n",
      "Training loss = 1.128000\n",
      "Validation loss = 1.199672\n",
      "### EPOCH 8 ###\n",
      "Training loss = 1.121444\n",
      "Validation loss = 1.207963\n",
      "### EPOCH 9 ###\n",
      "Training loss = 1.109026\n",
      "Validation loss = 1.201201\n",
      "### EPOCH 10 ###\n",
      "Training loss = 1.101988\n",
      "Validation loss = 1.206915\n",
      "### EPOCH 11 ###\n",
      "Training loss = 1.095814\n",
      "Validation loss = 1.202155\n",
      "### EPOCH 12 ###\n",
      "Training loss = 1.088542\n",
      "Validation loss = 1.198153\n",
      "### EPOCH 13 ###\n",
      "Training loss = 1.080476\n",
      "Validation loss = 1.201595\n",
      "### EPOCH 14 ###\n",
      "Training loss = 1.079334\n",
      "Validation loss = 1.212392\n",
      "### EPOCH 15 ###\n",
      "Training loss = 1.076605\n",
      "Validation loss = 1.209416\n",
      "### EPOCH 16 ###\n",
      "Training loss = 1.074980\n",
      "Validation loss = 1.204406\n",
      "### EPOCH 17 ###\n",
      "Training loss = 1.070671\n",
      "Validation loss = 1.207018\n",
      "### EPOCH 18 ###\n",
      "Training loss = 1.066261\n",
      "Validation loss = 1.206883\n",
      "### EPOCH 19 ###\n",
      "Training loss = 1.064938\n",
      "Validation loss = 1.210144\n",
      "### EPOCH 20 ###\n",
      "Training loss = 1.066512\n",
      "Validation loss = 1.210374\n",
      "### EPOCH 21 ###\n",
      "Training loss = 1.060281\n",
      "Validation loss = 1.209851\n",
      "### EPOCH 22 ###\n",
      "Training loss = 1.060149\n",
      "Validation loss = 1.208971\n",
      "### EPOCH 23 ###\n",
      "Training loss = 1.057868\n",
      "Validation loss = 1.214251\n",
      "### EPOCH 24 ###\n",
      "Training loss = 1.056929\n",
      "Validation loss = 1.209878\n",
      "### EPOCH 25 ###\n",
      "Training loss = 1.052029\n",
      "Validation loss = 1.210665\n",
      "### EPOCH 26 ###\n",
      "Training loss = 1.050705\n",
      "Validation loss = 1.210953\n",
      "### EPOCH 27 ###\n",
      "Training loss = 1.049701\n",
      "Validation loss = 1.211925\n",
      "### EPOCH 28 ###\n",
      "Training loss = 1.046884\n",
      "Validation loss = 1.213320\n",
      "### EPOCH 29 ###\n",
      "Training loss = 1.044536\n",
      "Validation loss = 1.206847\n",
      "### EPOCH 30 ###\n",
      "Training loss = 1.043070\n",
      "Validation loss = 1.210677\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21524b9e128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import rbm\n",
    "import projectLib as lib\n",
    "\n",
    "training = lib.getTrainingData()\n",
    "validation = lib.getValidationData()\n",
    "# You could also try with the chapter 4 data\n",
    "# training = lib.getChapter4Data()\n",
    "\n",
    "trStats = lib.getUsefulStats(training)\n",
    "vlStats = lib.getUsefulStats(validation)\n",
    "\n",
    "K = 5\n",
    "alpha = 0.9\n",
    "\n",
    "# SET PARAMETERS HERE!!!\n",
    "# number of hidden units\n",
    "F = 20\n",
    "epochs = 30\n",
    "gradientLearningRate = 0.0001\n",
    "gradientLearningRate_v = 0.001\n",
    "gradientLearningRate_h = 0.001\n",
    "_lambda = 1\n",
    "num_movies=trStats[\"n_movies\"]\n",
    "num_users=trStats[\"n_users\"]\n",
    "# Initialise all our arrays\n",
    "W = getInitialWeights(trStats[\"n_movies\"], F, K)\n",
    "posprods = np.zeros(W.shape)\n",
    "negprods = np.zeros(W.shape)\n",
    "m_w=np.zeros((W.shape[0],F,5))\n",
    "train_loss = []\n",
    "validation_loss = []\n",
    "vis_bias=np.zeros((num_movies,5))\n",
    "m_v=np.zeros((num_movies,5))\n",
    "hid_bias=np.zeros((F,))\n",
    "m_h=np.zeros((F,))\n",
    "for epoch in range(1, epochs+1):\n",
    "    # in each epoch, we'll visit all users in a random order\n",
    "    visitingOrder = np.array(trStats[\"u_users\"])\n",
    "    np.random.shuffle(visitingOrder)\n",
    "\n",
    "    for user in visitingOrder:\n",
    "        # get the ratings of that user\n",
    "        ratingsForUser = lib.getRatingsForUser(user, training)\n",
    "\n",
    "        # build the visible input\n",
    "        v = getV(ratingsForUser)\n",
    "\n",
    "        # get the weights associated to movies the user has seen\n",
    "        weightsForUser = W[ratingsForUser[:, 0], :, :]\n",
    "        \n",
    "        ### LEARNING ###\n",
    "        # propagate visible input to hidden units\n",
    "        posHiddenProb = visibleToHiddenVec(v, weightsForUser,hid_bias)\n",
    "        # get positive gradient\n",
    "        # note that we only update the movies that this user has seen!\n",
    "        posprods[ratingsForUser[:, 0], :, :] += probProduct(v, posHiddenProb)\n",
    "\n",
    "        ### UNLEARNING ###\n",
    "        # sample from hidden distribution\n",
    "        sampledHidden = sample(posHiddenProb)\n",
    "        # propagate back to get \"negative data\"\n",
    "        negData = hiddenToVisible(sampledHidden, weightsForUser,vis_bias[ratingsForUser[:,0]])\n",
    "        # propagate negative data to hidden units\n",
    "        negHiddenProb = visibleToHiddenVec(negData, weightsForUser,hid_bias)\n",
    "        # get negative gradient\n",
    "        # note that we only update the movies that this user has seen!\n",
    "        negprods[ratingsForUser[:, 0], :, :] += probProduct(negData, negHiddenProb)\n",
    "\n",
    "        poshidact = sum(posHiddenProb)\n",
    "        posvisact = sum(v)\n",
    "        neghidact = sum(negHiddenProb)\n",
    "        negvisact = sum(negData)\n",
    "        # we average over the number of users in the batch (if we use mini-batch)\n",
    "        grad_w = (gradientLearningRate/epoch) * (posprods - negprods)\n",
    "\n",
    "        m_w = alpha*m_w+grad_w\n",
    "        m_v = alpha*m_v+(gradientLearningRate_v) * (posvisact - negvisact)\n",
    "        m_h = alpha*m_h+(gradientLearningRate_h) * (poshidact - neghidact)\n",
    "        \n",
    "        W += m_w\n",
    "        vis_bias+=m_v\n",
    "        hid_bias+=m_h\n",
    "        \n",
    "    # Print the current RMSE for training and validation sets\n",
    "    # this allows you to control for overfitting e.g\n",
    "    # We predict over the training set\n",
    "    tr_r_hat = predict(trStats[\"movies\"], trStats[\"users\"], W, training,vis_bias,hid_bias)\n",
    "#     print (tr_r_hat)\n",
    "    trRMSE = lib.rmse(trStats[\"ratings\"], tr_r_hat)\n",
    "#     print (trRMSE)\n",
    "\n",
    "    # We predict over the validation set\n",
    "    vl_r_hat = predict(vlStats[\"movies\"], vlStats[\"users\"], W, training,vis_bias,hid_bias)\n",
    "#     vl_r_hat\n",
    "    vlRMSE = lib.rmse(vlStats[\"ratings\"], vl_r_hat)\n",
    "    \n",
    "    train_loss.append(trRMSE)\n",
    "    validation_loss.append(vlRMSE)\n",
    "\n",
    "    print (\"### EPOCH %d ###\" % epoch)\n",
    "    print (\"Training loss = %f\" % trRMSE)\n",
    "    print (\"Validation loss = %f\" % vlRMSE)\n",
    "\n",
    "### END ###\n",
    "# This part you can write on your own\n",
    "# you could plot the evolution of the training and validation RMSEs for example\n",
    "# predictedRatings = np.array([predictForUser(user, W, training) for user in trStats[\"u_users\"]])\n",
    "# np.savetxt(\"predictedRatings.txt\", predictedRatings)\n",
    "# fig1 = plt.figure()\n",
    "# ax1 = fig1.add_subplot(121)\n",
    "# ax1.plot(train_loss)\n",
    "# ax2 = fig1.add_subplot(122)\n",
    "# ax2.plot(validation_loss)\n",
    "\n",
    "plt.plot(train_loss)\n",
    "plt.plot(validation_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.shape(posprods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vlStats[\"users\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min(vl_r_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(train_loss)\n",
    "plt.plot(validation_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
