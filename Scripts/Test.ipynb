{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rbm\n",
    "import numpy as np\n",
    "import projectLib as lib\n",
    "import matplotlib.pyplot as plt\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F=5\n",
    "K=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = lib.getTrainingData()\n",
    "ratingsForUser1 = lib.getRatingsForUser(1, training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratingsPerMovie(training)\n",
    "v = rbm.getV(ratingsForUser1)\n",
    "# v.shape\n",
    "w = rbm.getInitialWeights(v.shape[0],F,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trStats = lib.getUsefulStats(training)\n",
    "W = rbm.getInitialWeights(trStats[\"n_movies\"], F, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_movies=trStats[\"n_movies\"]\n",
    "vis_bias=np.zeros((num_movies,5))\n",
    "hid_bias=np.zeros((F,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = [0,1,0,1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbm.hiddenToVisible(h, W[ratingsForUser1[:, 0], :, :])\n",
    "h = [0,1,0,1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbm.getPredictedDistribution(v, W[ratingsForUser1[:, 0], :, :], W[1, :, :], vis_bias, hid_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %load mainrbm.py\n",
    "import numpy as np\n",
    "import rbm\n",
    "import projectLib as lib\n",
    "import matplotlib.pyplot as plt\n",
    "import inspect\n",
    "\n",
    "training = lib.getTrainingData()\n",
    "validation = lib.getValidationData()\n",
    "# You could also try with the chapter 4 data\n",
    "# training = lib.getChapter4Data()\n",
    "\n",
    "trStats = lib.getUsefulStats(training)\n",
    "vlStats = lib.getUsefulStats(validation)\n",
    "\n",
    "K = 5\n",
    "alpha = 0.9\n",
    "\n",
    "# SET PARAMETERS HERE!!!\n",
    "# number of hidden units\n",
    "F = 5\n",
    "epochs = 30\n",
    "gradientLearningRate = 0.0001\n",
    "gradientLearningRate_v = 0.001\n",
    "gradientLearningRate_h = 0.001\n",
    "_lambda = 1\n",
    "minibatch_size = 10\n",
    "\n",
    "def adaptiveLearn(learning_rate_type=['constant','adapt','time', 'step', 'exponential'], \n",
    "                  lr=0.0001, k=0.1, epoch=None, drop=0.5, epochs_drop=10.0):\n",
    "#time-based decay, step decay and exponential decay\n",
    "    if learning_rate_type == 'constant':\n",
    "        return lr\n",
    "    elif learning_rate_type == 'adapt':\n",
    "        return lr/(epoch**2)\n",
    "    elif learning_rate_type == 'time':\n",
    "        return lr/(1.0+k*epoch)\n",
    "    elif learning_rate_type == 'step':\n",
    "        return lr*np.power(drop,np.floor((1+epoch)/epochs_drop))\n",
    "    elif learning_rate_type == 'exponential':\n",
    "        return lr*np.exp(-k*epoch)\n",
    "    \n",
    "def batch_get(array, B):\n",
    "    ret = []\n",
    "    for i in range(int(len(array)/B)):\n",
    "        ret.append(array[i*B:i*B+B])\n",
    "    if len(array)%B != 0:\n",
    "        ret.append(array[len(array)/B:])\n",
    "    return ret\n",
    "\n",
    "def main_rbm(training=training, validation=validation, trStats=trStats, vlStats=vlStats, \n",
    "             K=5, F=5, epochs=30, gradientLearningRate=0.0001,gradientLearningRate_v = 0.0001,\n",
    "             gradientLearningRate_h = 0.0001, minibatch_size=10, alpha=0.9, \n",
    "             stopping=False, momentum=False, learning_rate_type='time', learning_rate_k=0.1, \n",
    "             learning_rate_drop=0.5, learning_rate_epochs_drop=10.0, _lambda = 0.3):\n",
    "    \n",
    "    # Print current hyperparams\n",
    "#     frame = inspect.currentframe()\n",
    "#     args, _, _, values = inspect.getargvalues(frame)\n",
    "#     print ('Training and Predicting with the following hyperparameters:')\n",
    "#     for i in args[4:]:\n",
    "#         print (\"    %s = %s\" % (i, values[i]))\n",
    "        \n",
    "    # Initialise all our arrays\n",
    "    num_movies=trStats[\"n_movies\"]\n",
    "    num_users=trStats[\"n_users\"]\n",
    "    W = rbm.getInitialWeights(trStats[\"n_movies\"], F, K)\n",
    "    posprods = np.zeros(W.shape)\n",
    "    negprods = np.zeros(W.shape)\n",
    "    grad_w = np.zeros(W.shape)\n",
    "    m_w=np.zeros((W.shape[0],F,5))\n",
    "    train_loss = []\n",
    "    validation_loss = []\n",
    "    vis_bias=np.zeros((num_movies,5))\n",
    "    m_v=np.zeros((num_movies,5))\n",
    "    hid_bias=np.zeros((F,))\n",
    "    m_h=np.zeros((F,))\n",
    "    best_train_loss = 100\n",
    "    best_validation_loss = 100\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "    #     mini_batch_grads = []\n",
    "        # in each epoch, we'll visit all users in a random order\n",
    "        visitingOrder = np.array(trStats[\"u_users\"])\n",
    "        np.random.shuffle(visitingOrder)\n",
    "#         for i in range(0, visitingOrder.shape[0], minibatch_size):\n",
    "#                 # Get pair of (X, y) of the current minibatch/chunk\n",
    "#             visitingOrderMini = visitingOrder[i:i + minibatch_size]\n",
    "#                 y_train_mini = y_train[i:i + minibatch_size]\n",
    "#         for i in range(0, visitingOrder.shape[0], minibatch_size):\n",
    "        batches = batch_get(visitingOrder, minibatch_size)\n",
    "        poshidact,posvisact,neghidact,negvisact = 0,0,0,0\n",
    "        for batch in batches:\n",
    "            prev_grad = grad_w\n",
    "            grad_w = np.zeros(W.shape)\n",
    "            for user in batch:\n",
    "                # get the ratings of that user\n",
    "                ratingsForUser = lib.getRatingsForUser(user, training)\n",
    "\n",
    "                # build the visible input\n",
    "                v = rbm.getV(ratingsForUser)\n",
    "\n",
    "                # get the weights associated to movies the user has seen\n",
    "                weightsForUser = W[ratingsForUser[:, 0], :, :]\n",
    "\n",
    "                ### LEARNING ###\n",
    "                # propagate visible input to hidden units\n",
    "                posHiddenProb = rbm.visibleToHiddenVec(v, weightsForUser,hid_bias) #, hid_bias)\n",
    "                # get positive gradient\n",
    "                # note that we only update the movies that this user has seen!\n",
    "                posprods[ratingsForUser[:, 0], :, :] += rbm.probProduct(v, posHiddenProb)\n",
    "\n",
    "                ### UNLEARNING ###\n",
    "                # sample from hidden distribution\n",
    "                sampledHidden = rbm.sample(posHiddenProb)\n",
    "                # propagate back to get \"negative data\"\n",
    "                negData = rbm.hiddenToVisible(sampledHidden, weightsForUser,vis_bias[ratingsForUser[:,0]])#, vis_bias[ratingsForUser[:,0]])\n",
    "                # propagate negative data to hidden units\n",
    "                negHiddenProb = rbm.visibleToHiddenVec(negData, weightsForUser,hid_bias) #, hid_bias)\n",
    "                # get negative gradient\n",
    "                # note that we only update the movies that this user has seen!\n",
    "                negprods[ratingsForUser[:, 0], :, :] += rbm.probProduct(negData, negHiddenProb)\n",
    "\n",
    "                poshidact += sum(posHiddenProb)\n",
    "                posvisact += sum(v)\n",
    "                neghidact += sum(negHiddenProb)\n",
    "                negvisact += sum(negData)\n",
    "                # we average over the number of users in the batch (if we use mini-batch)\n",
    "    #             grad = (gradientLearningRate/epoch)*(posprods-negprods)\n",
    "                '''\n",
    "                Regularization - \n",
    "                '''\n",
    "                grad_w += adaptiveLearn(learning_rate_type=learning_rate_type, k=learning_rate_k, \n",
    "                                        drop=learning_rate_drop, epochs_drop=learning_rate_epochs_drop, \n",
    "                                        epoch=epoch)*((posprods-negprods)/trStats[\"n_users\"]-_lambda*W)\n",
    "        #         mini_batch_grads.append(grad)\n",
    "\n",
    "            #     m = alpha*m+grad\n",
    "                '''\n",
    "                Ask about the implementation of biases (should we create matrix of biases for hidden and visible layers?)\n",
    "                '''\n",
    "            m_w = alpha*m_w + grad_w\n",
    "            m_v = alpha*m_v+(gradientLearningRate_v) * (posvisact - negvisact)\n",
    "            m_h = alpha*m_h+(gradientLearningRate_h) * (poshidact - neghidact)\n",
    "\n",
    "            if momentum == False:\n",
    "                W += grad_w\n",
    "            else:\n",
    "                W += m_w\n",
    "\n",
    "            vis_bias += m_v\n",
    "            hid_bias += m_h\n",
    "\n",
    "        # Print the current RMSE for training and validation sets\n",
    "        # this allows you to control for overfitting e.g\n",
    "        # We predict over the training set\n",
    "        tr_r_hat = rbm.predict(trStats[\"movies\"], trStats[\"users\"], W, training,vis_bias,hid_bias) #, vis_bias, hid_bias, predictType='exp')\n",
    "    #     print (tr_r_hat)\n",
    "        trRMSE = lib.rmse(trStats[\"ratings\"], tr_r_hat)\n",
    "    #     print (trRMSE)\n",
    "        if trRMSE < best_train_loss:\n",
    "            best_train_loss = trRMSE\n",
    "            best_training_weights = W\n",
    "            best_train_predictions = tr_r_hat\n",
    "\n",
    "        # We predict over the validation set\n",
    "        vl_r_hat = rbm.predict(vlStats[\"movies\"], vlStats[\"users\"], W, training,vis_bias,hid_bias) #, vis_bias, hid_bias, predictType='exp')\n",
    "    #     vl_r_hat\n",
    "        vlRMSE = lib.rmse(vlStats[\"ratings\"], vl_r_hat)\n",
    "        if vlRMSE < best_validation_loss:\n",
    "            best_validation_loss = vlRMSE\n",
    "            best_validation_weights = W\n",
    "            best_validation_predictions = vl_r_hat\n",
    "            best_vis_bias = vis_bias\n",
    "            best_hid_bias = hid_bias\n",
    "#             best_momentum = momentum\n",
    "#             best_reg = regularization\n",
    "#             best_epoch = epoch\n",
    "#             best_alpha = alpha\n",
    "#             best_B = B\n",
    "#             best_F = F\n",
    "#             min_rmse = vlRMSE\n",
    "#                     print('Best RMSE:', min_rmse)\n",
    "\n",
    "        train_loss.append(trRMSE)\n",
    "        validation_loss.append(vlRMSE)\n",
    "\n",
    "        print (\"### EPOCH %d ###\" % epoch)\n",
    "        print (\"Training loss = %f\" % trRMSE)\n",
    "        print (\"Validation loss = %f\" % vlRMSE)\n",
    "\n",
    "    ### END ###\n",
    "    # This part you can write on your own\n",
    "    # you could plot the evolution of the training and validation RMSEs for example\n",
    "    # predictedRatings = np.array([predictForUser(user, W, training) for user in trStats[\"u_users\"]])\n",
    "    # np.savetxt(\"predictedRatings.txt\", predictedRatings)\n",
    "    # fig1 = plt.figure()\n",
    "    # ax1 = fig1.add_subplot(121)\n",
    "    # ax1.plot(train_loss)\n",
    "    # ax2 = fig1.add_subplot(122)\n",
    "    # ax2.plot(validation_loss)\n",
    "    \n",
    "    plt.plot(train_loss)\n",
    "    plt.plot(validation_loss)\n",
    "    plt.show()\n",
    "    if stopping==True:\n",
    "        print('Best training loss = %f' % best_train_loss)\n",
    "        print('Best validation loss = %f' % best_validation_loss)\n",
    "    else:\n",
    "        print('Final training loss = %f' % trRMSE)\n",
    "        print('Final validation loss = %f' % vlRMSE)\n",
    "    return [best_validation_loss, best_validation_predictions, best_validation_weights, best_vis_bias, best_hid_bias]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### EPOCH 1 ###\n",
      "Training loss = 1.212948\n",
      "Validation loss = 1.237642\n",
      "### EPOCH 2 ###\n",
      "Training loss = 1.212118\n",
      "Validation loss = 1.237540\n",
      "### EPOCH 3 ###\n",
      "Training loss = 1.211934\n",
      "Validation loss = 1.236046\n",
      "### EPOCH 4 ###\n",
      "Training loss = 1.211350\n",
      "Validation loss = 1.235989\n",
      "### EPOCH 5 ###\n",
      "Training loss = 1.210170\n",
      "Validation loss = 1.234543\n",
      "### EPOCH 6 ###\n",
      "Training loss = 1.209901\n",
      "Validation loss = 1.232846\n",
      "### EPOCH 7 ###\n",
      "Training loss = 1.209575\n",
      "Validation loss = 1.233661\n",
      "### EPOCH 8 ###\n",
      "Training loss = 1.209530\n",
      "Validation loss = 1.233047\n",
      "### EPOCH 9 ###\n",
      "Training loss = 1.208982\n",
      "Validation loss = 1.232754\n",
      "### EPOCH 10 ###\n",
      "Training loss = 1.208381\n",
      "Validation loss = 1.232253\n",
      "### EPOCH 11 ###\n",
      "Training loss = 1.207930\n",
      "Validation loss = 1.232406\n",
      "### EPOCH 12 ###\n",
      "Training loss = 1.207668\n",
      "Validation loss = 1.231578\n",
      "### EPOCH 13 ###\n",
      "Training loss = 1.207554\n",
      "Validation loss = 1.232297\n",
      "### EPOCH 14 ###\n",
      "Training loss = 1.207176\n",
      "Validation loss = 1.231020\n",
      "### EPOCH 15 ###\n",
      "Training loss = 1.206571\n",
      "Validation loss = 1.230581\n",
      "### EPOCH 16 ###\n",
      "Training loss = 1.206043\n",
      "Validation loss = 1.229861\n",
      "### EPOCH 17 ###\n",
      "Training loss = 1.205318\n",
      "Validation loss = 1.228929\n",
      "### EPOCH 18 ###\n",
      "Training loss = 1.204692\n",
      "Validation loss = 1.228984\n",
      "### EPOCH 19 ###\n",
      "Training loss = 1.204442\n",
      "Validation loss = 1.229146\n",
      "### EPOCH 20 ###\n",
      "Training loss = 1.203900\n",
      "Validation loss = 1.228221\n",
      "### EPOCH 21 ###\n",
      "Training loss = 1.203760\n",
      "Validation loss = 1.227363\n",
      "### EPOCH 22 ###\n",
      "Training loss = 1.203381\n",
      "Validation loss = 1.226765\n",
      "### EPOCH 23 ###\n",
      "Training loss = 1.202094\n",
      "Validation loss = 1.227513\n",
      "### EPOCH 24 ###\n",
      "Training loss = 1.201903\n",
      "Validation loss = 1.226021\n",
      "### EPOCH 25 ###\n",
      "Training loss = 1.201372\n",
      "Validation loss = 1.226986\n",
      "### EPOCH 26 ###\n",
      "Training loss = 1.200644\n",
      "Validation loss = 1.226037\n",
      "### EPOCH 27 ###\n",
      "Training loss = 1.200292\n",
      "Validation loss = 1.226325\n",
      "### EPOCH 28 ###\n",
      "Training loss = 1.199592\n",
      "Validation loss = 1.224940\n",
      "### EPOCH 29 ###\n",
      "Training loss = 1.198743\n",
      "Validation loss = 1.225080\n",
      "### EPOCH 30 ###\n",
      "Training loss = 1.198800\n",
      "Validation loss = 1.223033\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best training loss = 1.198743\n",
      "Best validation loss = 1.223033\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-f1635268bf79>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m                                  \u001b[0mminibatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstopping\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                                  \u001b[0mlearning_rate_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate_k\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate_drop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                                  learning_rate_epochs_drop=10.0, _lambda = regularization)\n\u001b[0m\u001b[0;32m     29\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mmin_rmse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m                         \u001b[0mbest_momentum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-05c74020e20a>\u001b[0m in \u001b[0;36mmain_rbm\u001b[1;34m(training, validation, trStats, vlStats, K, F, epochs, gradientLearningRate, gradientLearningRate_v, gradientLearningRate_h, minibatch_size, alpha, stopping, momentum, learning_rate_type, learning_rate_k, learning_rate_drop, learning_rate_epochs_drop, _lambda)\u001b[0m\n\u001b[0;32m    155\u001b[0m         \u001b[1;31m# this allows you to control for overfitting e.g\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[1;31m# We predict over the training set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m         \u001b[0mtr_r_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrStats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"movies\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrStats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"users\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvis_bias\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhid_bias\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#, vis_bias, hid_bias, predictType='exp')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m     \u001b[1;31m#     print (tr_r_hat)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[0mtrRMSE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrmse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrStats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ratings\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtr_r_hat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\ESD\\Networked Life\\Project\\01.104 Test\\Scripts\\rbm.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(movies, users, W, training, vis_bias, hid_bias, predictType)\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[1;31m# given a list of movies and users, predict the rating for each (movie, user) pair\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m     \u001b[1;31m# used to compute RMSE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpredictMovieForUser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmovie\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvis_bias\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhid_bias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictType\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpredictType\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmovie\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmovies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpredictForUser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvis_bias\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhid_bias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictType\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"exp\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\ESD\\Networked Life\\Project\\01.104 Test\\Scripts\\rbm.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[1;31m# given a list of movies and users, predict the rating for each (movie, user) pair\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m     \u001b[1;31m# used to compute RMSE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpredictMovieForUser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmovie\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvis_bias\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhid_bias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictType\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpredictType\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmovie\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmovies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpredictForUser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvis_bias\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhid_bias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictType\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"exp\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\ESD\\Networked Life\\Project\\01.104 Test\\Scripts\\rbm.py\u001b[0m in \u001b[0;36mpredictMovieForUser\u001b[1;34m(q, user, W, training, vis_bias, hid_bias, predictType)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[0mratingsForUser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetRatingsForUser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mratingsForUser\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m     \u001b[0mratingDistribution\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetPredictedDistribution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mratingsForUser\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvis_bias\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhid_bias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpredictType\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"max\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpredictRatingMax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mratingDistribution\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\ESD\\Networked Life\\Project\\01.104 Test\\Scripts\\rbm.py\u001b[0m in \u001b[0;36mgetPredictedDistribution\u001b[1;34m(v, w, wq, vis_bias, hid_bias)\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[0msampledHidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposHiddenProb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[0mwq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mwq\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m     \u001b[0mnegData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhiddenToVisible\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msampledHidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvis_bias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnegData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\ESD\\Networked Life\\Project\\01.104 Test\\Scripts\\rbm.py\u001b[0m in \u001b[0;36mhiddenToVisible\u001b[1;34m(h, w, vis_bias)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;31m#     return sig(output+vis_bias)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m     \u001b[0msummation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensordot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;31m# print(summation.shape) # (m,5)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;31m# print(summation[0,:])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36mtensordot\u001b[1;34m(a, b, axes)\u001b[0m\n\u001b[0;32m   1391\u001b[0m     \u001b[0mat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewaxes_a\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewshape_a\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1392\u001b[0m     \u001b[0mbt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewaxes_b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewshape_b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1393\u001b[1;33m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1394\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0molda\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0moldb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Hyperparameter tuning:\n",
    "\n",
    "# mrange = np.linspace(0.7,0.95,5)\n",
    "mrange = [0.7, 0.8, 0.9]\n",
    "# rrange = np.linspace(0.1,0.9,5)\n",
    "rrange = [0.1, 0.5, 0.9]\n",
    "arange = [0.0001, 0.001, 0.01]\n",
    "brange = [10]\n",
    "frange = [5, 10, 20]\n",
    "\n",
    "best_momentum = 0\n",
    "best_reg = 0\n",
    "best_lr = 0\n",
    "best_batch = 0\n",
    "best_F = 0\n",
    "\n",
    "min_rmse=10\n",
    "for momentum in mrange:\n",
    "    for regularization in rrange:\n",
    "        for learning_rate in arange:\n",
    "            for batch in brange:\n",
    "                for F in frange:\n",
    "                    prediction = main_rbm(training=training, validation=validation, trStats=trStats, vlStats=vlStats, \n",
    "                                 K=5, F=int(F), epochs=30, gradientLearningRate=learning_rate, \n",
    "                                 gradientLearningRate_v = 0.0001/int(batch), gradientLearningRate_h = 0.0001/int(batch), \n",
    "                                 minibatch_size=int(batch), alpha=momentum, stopping=True, momentum=True, \n",
    "                                 learning_rate_type='time', learning_rate_k=0.5, learning_rate_drop=0.5, \n",
    "                                 learning_rate_epochs_drop=10.0, _lambda = regularization)\n",
    "                    if prediction[0] < min_rmse:\n",
    "                        best_momentum = momentum\n",
    "                        best_reg = regularization\n",
    "#                             best_epoch = epoch\n",
    "                        best_lr = learning_rate\n",
    "                        best_batch = batch\n",
    "                        best_F = F\n",
    "                        best_predict = prediction[1]\n",
    "                        min_rmse = prediction[0]\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Tune other parameters and add biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### EPOCH 1 ###\n",
      "Training loss = 1.211930\n",
      "Validation loss = 1.235794\n",
      "### EPOCH 2 ###\n",
      "Training loss = 1.209490\n",
      "Validation loss = 1.233754\n",
      "### EPOCH 3 ###\n",
      "Training loss = 1.208207\n",
      "Validation loss = 1.232847\n",
      "### EPOCH 4 ###\n",
      "Training loss = 1.207020\n",
      "Validation loss = 1.232066\n",
      "### EPOCH 5 ###\n",
      "Training loss = 1.206327\n",
      "Validation loss = 1.230266\n",
      "### EPOCH 6 ###\n",
      "Training loss = 1.204783\n",
      "Validation loss = 1.228607\n",
      "### EPOCH 7 ###\n",
      "Training loss = 1.203338\n",
      "Validation loss = 1.228524\n",
      "### EPOCH 8 ###\n",
      "Training loss = 1.201840\n",
      "Validation loss = 1.226398\n",
      "### EPOCH 9 ###\n",
      "Training loss = 1.198740\n",
      "Validation loss = 1.224017\n",
      "### EPOCH 10 ###\n",
      "Training loss = 1.196938\n",
      "Validation loss = 1.221863\n",
      "### EPOCH 11 ###\n",
      "Training loss = 1.194899\n",
      "Validation loss = 1.221372\n",
      "### EPOCH 12 ###\n",
      "Training loss = 1.192711\n",
      "Validation loss = 1.219628\n",
      "### EPOCH 13 ###\n",
      "Training loss = 1.191424\n",
      "Validation loss = 1.217476\n",
      "### EPOCH 14 ###\n",
      "Training loss = 1.189401\n",
      "Validation loss = 1.216727\n",
      "### EPOCH 15 ###\n",
      "Training loss = 1.188605\n",
      "Validation loss = 1.215705\n",
      "### EPOCH 16 ###\n",
      "Training loss = 1.186563\n",
      "Validation loss = 1.214521\n",
      "### EPOCH 17 ###\n",
      "Training loss = 1.185287\n",
      "Validation loss = 1.214923\n",
      "### EPOCH 18 ###\n",
      "Training loss = 1.183890\n",
      "Validation loss = 1.211461\n",
      "### EPOCH 19 ###\n",
      "Training loss = 1.182511\n",
      "Validation loss = 1.210094\n",
      "### EPOCH 20 ###\n",
      "Training loss = 1.181290\n",
      "Validation loss = 1.210206\n",
      "### EPOCH 21 ###\n",
      "Training loss = 1.181116\n",
      "Validation loss = 1.211151\n",
      "### EPOCH 22 ###\n",
      "Training loss = 1.180361\n",
      "Validation loss = 1.209390\n",
      "### EPOCH 23 ###\n",
      "Training loss = 1.180016\n",
      "Validation loss = 1.208810\n",
      "### EPOCH 24 ###\n",
      "Training loss = 1.179708\n",
      "Validation loss = 1.209673\n",
      "### EPOCH 25 ###\n",
      "Training loss = 1.179733\n",
      "Validation loss = 1.208099\n",
      "### EPOCH 26 ###\n",
      "Training loss = 1.179574\n",
      "Validation loss = 1.209061\n",
      "### EPOCH 27 ###\n",
      "Training loss = 1.179178\n",
      "Validation loss = 1.208274\n",
      "### EPOCH 28 ###\n",
      "Training loss = 1.179950\n",
      "Validation loss = 1.210552\n",
      "### EPOCH 29 ###\n",
      "Training loss = 1.178826\n",
      "Validation loss = 1.208655\n",
      "### EPOCH 30 ###\n",
      "Training loss = 1.178246\n",
      "Validation loss = 1.208876\n",
      "### EPOCH 31 ###\n",
      "Training loss = 1.179050\n",
      "Validation loss = 1.210929\n",
      "### EPOCH 32 ###\n",
      "Training loss = 1.179088\n",
      "Validation loss = 1.210484\n",
      "### EPOCH 33 ###\n",
      "Training loss = 1.178991\n",
      "Validation loss = 1.209013\n",
      "### EPOCH 34 ###\n",
      "Training loss = 1.178550\n",
      "Validation loss = 1.209266\n",
      "### EPOCH 35 ###\n",
      "Training loss = 1.178674\n",
      "Validation loss = 1.210210\n",
      "### EPOCH 36 ###\n",
      "Training loss = 1.178795\n",
      "Validation loss = 1.209975\n",
      "### EPOCH 37 ###\n",
      "Training loss = 1.176699\n",
      "Validation loss = 1.211786\n",
      "### EPOCH 38 ###\n",
      "Training loss = 1.178882\n",
      "Validation loss = 1.209622\n",
      "### EPOCH 39 ###\n",
      "Training loss = 1.177759\n",
      "Validation loss = 1.211572\n",
      "### EPOCH 40 ###\n",
      "Training loss = 1.177483\n",
      "Validation loss = 1.209890\n",
      "### EPOCH 41 ###\n",
      "Training loss = 1.177366\n",
      "Validation loss = 1.208645\n",
      "### EPOCH 42 ###\n",
      "Training loss = 1.177469\n",
      "Validation loss = 1.208597\n",
      "### EPOCH 43 ###\n",
      "Training loss = 1.176790\n",
      "Validation loss = 1.210351\n",
      "### EPOCH 44 ###\n",
      "Training loss = 1.176560\n",
      "Validation loss = 1.208630\n",
      "### EPOCH 45 ###\n",
      "Training loss = 1.176859\n",
      "Validation loss = 1.209698\n",
      "### EPOCH 46 ###\n",
      "Training loss = 1.176963\n",
      "Validation loss = 1.206062\n",
      "### EPOCH 47 ###\n",
      "Training loss = 1.178470\n",
      "Validation loss = 1.211331\n",
      "### EPOCH 48 ###\n",
      "Training loss = 1.176545\n",
      "Validation loss = 1.210003\n",
      "### EPOCH 49 ###\n",
      "Training loss = 1.176186\n",
      "Validation loss = 1.210246\n",
      "### EPOCH 50 ###\n",
      "Training loss = 1.176509\n",
      "Validation loss = 1.206291\n",
      "### EPOCH 51 ###\n",
      "Training loss = 1.175804\n",
      "Validation loss = 1.207506\n",
      "### EPOCH 52 ###\n",
      "Training loss = 1.176988\n",
      "Validation loss = 1.208077\n",
      "### EPOCH 53 ###\n",
      "Training loss = 1.176567\n",
      "Validation loss = 1.208888\n",
      "### EPOCH 54 ###\n",
      "Training loss = 1.176326\n",
      "Validation loss = 1.209885\n",
      "### EPOCH 55 ###\n",
      "Training loss = 1.177134\n",
      "Validation loss = 1.207840\n",
      "### EPOCH 56 ###\n",
      "Training loss = 1.176670\n",
      "Validation loss = 1.208296\n",
      "### EPOCH 57 ###\n",
      "Training loss = 1.175459\n",
      "Validation loss = 1.209134\n",
      "### EPOCH 58 ###\n",
      "Training loss = 1.175965\n",
      "Validation loss = 1.206660\n",
      "### EPOCH 59 ###\n",
      "Training loss = 1.175979\n",
      "Validation loss = 1.209721\n",
      "### EPOCH 60 ###\n",
      "Training loss = 1.176761\n",
      "Validation loss = 1.207332\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best training loss = 1.175459\n",
      "Best validation loss = 1.206062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2060624529736623,\n",
       " [2.9873346725396286,\n",
       "  2.9708720517727203,\n",
       "  2.9579567317991295,\n",
       "  3.0325449647720255,\n",
       "  3.049150329197403,\n",
       "  3.012709836264592,\n",
       "  3.0375198634303833,\n",
       "  3.0287671236820746,\n",
       "  2.9522746377046145,\n",
       "  3.0627892290854186,\n",
       "  3.0248369943042803,\n",
       "  2.99382208629799,\n",
       "  2.876909327218591,\n",
       "  3.019742259819378,\n",
       "  3.008917900326731,\n",
       "  3.0282791614557745,\n",
       "  2.992375299321121,\n",
       "  3.1925539947198196,\n",
       "  3.133547164907702,\n",
       "  2.9929930647243967,\n",
       "  3.022799774481742,\n",
       "  3.010006706763438,\n",
       "  2.9446947114267283,\n",
       "  2.9291608144731276,\n",
       "  3.1883619532464715,\n",
       "  2.983705177441306,\n",
       "  2.977692053878914,\n",
       "  2.946025044332269,\n",
       "  3.0006278660733754,\n",
       "  3.237855788289501,\n",
       "  3.1415111375055296,\n",
       "  2.9990730391929077,\n",
       "  3.0407895628526505,\n",
       "  2.994463376737305,\n",
       "  2.983408956753013,\n",
       "  3.1819889100024517,\n",
       "  3.0655473013172463,\n",
       "  3.008315060771278,\n",
       "  2.9140214068579735,\n",
       "  3.0373793617391778,\n",
       "  2.988596431308765,\n",
       "  3.0210785636020754,\n",
       "  3.003168547361086,\n",
       "  3.054629807771312,\n",
       "  2.946473852030201,\n",
       "  2.9453379437483607,\n",
       "  3.1836502876669175,\n",
       "  2.989776774879096,\n",
       "  3.1736939980716574,\n",
       "  2.9873346725396286,\n",
       "  2.964344619079542,\n",
       "  3.015399361550343,\n",
       "  2.9941156417852146,\n",
       "  3.2353787135470844,\n",
       "  2.96721013140123,\n",
       "  2.985953730994577,\n",
       "  2.9800794618880455,\n",
       "  3.0420663875080933,\n",
       "  3.2363018172539704,\n",
       "  2.904117189661149,\n",
       "  3.000109908428705,\n",
       "  2.9139624077523023,\n",
       "  2.887877230558429,\n",
       "  2.9890432660586126,\n",
       "  2.958616749539309,\n",
       "  3.006351817544692,\n",
       "  2.9873346725396286,\n",
       "  2.913199937642844,\n",
       "  2.9971461246448285,\n",
       "  3.1155595954295046,\n",
       "  2.976709793932443,\n",
       "  3.0819825599421877,\n",
       "  3.076443589960501,\n",
       "  3.014997433216854,\n",
       "  3.0221638253467047,\n",
       "  3.325372403655137,\n",
       "  2.987362801703855,\n",
       "  3.0091470418637707,\n",
       "  3.2421739505484624,\n",
       "  3.0307320456462414,\n",
       "  3.050036864083742,\n",
       "  3.0078546232512196,\n",
       "  2.9873346725396286,\n",
       "  3.061028474146014,\n",
       "  3.138526660306127,\n",
       "  2.958475486935135,\n",
       "  3.1410894447687827,\n",
       "  3.0164512748544863,\n",
       "  3.0044307474855225,\n",
       "  2.9583348549209325,\n",
       "  3.048559384726775,\n",
       "  3.0930170113959314,\n",
       "  3.1142787423839353,\n",
       "  3.0167041237886063,\n",
       "  2.9742343996165452,\n",
       "  3.0114648951402305,\n",
       "  3.0013999482826925,\n",
       "  2.9900069882904847,\n",
       "  3.0530940759422713,\n",
       "  3.1079812187953637,\n",
       "  3.026501808873531,\n",
       "  3.014815515019509,\n",
       "  2.967141866395106,\n",
       "  3.0604507147377724,\n",
       "  3.020544874581481,\n",
       "  2.984563406348153,\n",
       "  2.882984859555384,\n",
       "  3.0006278660733754,\n",
       "  2.984588373540736,\n",
       "  3.1701991945857357,\n",
       "  3.0525456611637956,\n",
       "  3.2079686818917343,\n",
       "  2.9338993365016353,\n",
       "  3.0529613098804163,\n",
       "  3.0882880488234585,\n",
       "  3.1888297576750277,\n",
       "  2.990335534090791,\n",
       "  3.0024305009550245,\n",
       "  2.966481504545999,\n",
       "  3.009753358152299,\n",
       "  3.14850053462742,\n",
       "  2.935526237735932,\n",
       "  2.980492441830127,\n",
       "  3.0328416790625,\n",
       "  3.1411783779445503,\n",
       "  2.9656135379333897,\n",
       "  3.067800363340865,\n",
       "  2.986896825789671,\n",
       "  2.9239517931236336,\n",
       "  2.8774853382369026,\n",
       "  3.00950586898535,\n",
       "  3.020336929176154,\n",
       "  2.9862494544883513,\n",
       "  2.804862034662453,\n",
       "  3.048406639671568,\n",
       "  2.949371330857964,\n",
       "  2.9596902003517096,\n",
       "  2.904611234342818,\n",
       "  2.938372538079534,\n",
       "  2.995091740357553,\n",
       "  3.04761735352012,\n",
       "  3.0053128665439077,\n",
       "  2.943221480634901,\n",
       "  2.9856640990258594,\n",
       "  3.0286648111247367,\n",
       "  3.0065407624063942,\n",
       "  2.906074095264564,\n",
       "  2.9989278268435076,\n",
       "  3.0424548709709676,\n",
       "  3.0049816951795507,\n",
       "  3.0122792147731032,\n",
       "  3.0335572128907446,\n",
       "  3.0124888111197494,\n",
       "  3.01186456639015,\n",
       "  2.86426860412886,\n",
       "  3.088854737106379,\n",
       "  2.959844246184819,\n",
       "  2.9855150597077866,\n",
       "  2.867182001000398,\n",
       "  2.979060498570725,\n",
       "  3.0167041237886063,\n",
       "  3.042431033766138,\n",
       "  2.988926100910534,\n",
       "  2.9988314332014907,\n",
       "  2.9892814068907843,\n",
       "  3.1991217870944038,\n",
       "  3.0405888234238647,\n",
       "  2.968226590066883,\n",
       "  3.1343527630321955,\n",
       "  2.9967234187237017,\n",
       "  2.9667612918993487,\n",
       "  2.9933917310908265,\n",
       "  3.0073680746849165,\n",
       "  3.0700701572150115,\n",
       "  2.9860606669566034,\n",
       "  3.001810680942274,\n",
       "  3.268279191844931,\n",
       "  3.0139254086827845,\n",
       "  2.980649393554851,\n",
       "  3.0029223773006244,\n",
       "  2.9949730216949177,\n",
       "  3.0046723499418047,\n",
       "  2.970379754266577,\n",
       "  2.950002381288085,\n",
       "  3.2347928567445727,\n",
       "  2.904858033262712,\n",
       "  3.1445488650462003,\n",
       "  3.1691011811621372,\n",
       "  2.9934441487504655,\n",
       "  3.008668477110837,\n",
       "  3.255371003781855,\n",
       "  2.9634992309946453,\n",
       "  2.840782080019583,\n",
       "  2.941364739207101,\n",
       "  3.087235258257765,\n",
       "  2.8937261830084373,\n",
       "  2.8645925078102,\n",
       "  3.0416220503841402,\n",
       "  2.9873346725396286,\n",
       "  3.018266765001991,\n",
       "  3.0086995242833927,\n",
       "  3.1391040453936427,\n",
       "  2.947243458072846,\n",
       "  3.1770783242004814,\n",
       "  2.9117581852090106,\n",
       "  3.0919962156502834,\n",
       "  3.086330151515139,\n",
       "  2.9827487673208744,\n",
       "  3.074818291700682,\n",
       "  2.9798572863954425,\n",
       "  3.050118735001461,\n",
       "  3.007725062123486,\n",
       "  3.035099987463633,\n",
       "  3.000881680423233,\n",
       "  2.9793015894901784,\n",
       "  2.8271013046684947,\n",
       "  2.8221530575897393,\n",
       "  3.0115359999161164,\n",
       "  3.161084424505482,\n",
       "  3.046664001628282,\n",
       "  3.0700701572150115,\n",
       "  2.9940738081612994,\n",
       "  2.9939387893714855,\n",
       "  3.013695391955223,\n",
       "  3.032817968747338,\n",
       "  3.1067487510256817,\n",
       "  3.0149240176565275,\n",
       "  2.9275441013204544,\n",
       "  2.991017335963517,\n",
       "  2.9841235016429124,\n",
       "  2.992342963452721,\n",
       "  3.16152225002313,\n",
       "  3.1494000982853088,\n",
       "  3.0275105381382,\n",
       "  2.990324165840345,\n",
       "  2.8943030870200435,\n",
       "  3.008406121853379,\n",
       "  3.005082821464984,\n",
       "  3.133547164907702,\n",
       "  2.971526665052387,\n",
       "  2.9939827030751287,\n",
       "  2.9605842448596245,\n",
       "  3.038695468522581,\n",
       "  3.139643136884596,\n",
       "  2.944840587412627,\n",
       "  3.100168643595321,\n",
       "  3.0321497871357166,\n",
       "  2.981812821716347,\n",
       "  3.00659879611862,\n",
       "  3.0055181189684133,\n",
       "  2.9992955455187316,\n",
       "  2.9447003224373534,\n",
       "  2.8119712517514257,\n",
       "  2.9292967915487966,\n",
       "  3.0753986451212167,\n",
       "  3.0605819632279845,\n",
       "  2.984223534116376,\n",
       "  3.00669084946687,\n",
       "  3.037559224965225,\n",
       "  3.013106605452688,\n",
       "  2.9991685386015035,\n",
       "  3.0766029064111513,\n",
       "  3.013748518816013,\n",
       "  2.9622432796872618,\n",
       "  2.961193193972052,\n",
       "  2.990207379122985,\n",
       "  2.915845219622975,\n",
       "  3.0810699303502944,\n",
       "  3.065530491929894,\n",
       "  2.9898080533220353,\n",
       "  2.9916064797950566,\n",
       "  2.9914468086942625,\n",
       "  3.0126818262424404,\n",
       "  2.991515779184411,\n",
       "  3.2264347569194287,\n",
       "  3.0584103628014896,\n",
       "  3.0210173480595595,\n",
       "  3.0982920001063317,\n",
       "  2.970913967284739,\n",
       "  2.9894456882431024,\n",
       "  3.1649736747059807,\n",
       "  3.0353917770298775,\n",
       "  2.9792668346940676,\n",
       "  3.074380188252006,\n",
       "  3.079753125518463,\n",
       "  3.1109601138751746,\n",
       "  3.1425521988055705,\n",
       "  2.9926652945451737,\n",
       "  2.9362365396340544,\n",
       "  3.081161355536982,\n",
       "  3.0639242261188167,\n",
       "  3.2320451026101775,\n",
       "  2.9867369607495027,\n",
       "  3.0669543951282936,\n",
       "  3.0373217323997226,\n",
       "  2.9011442450257996,\n",
       "  3.249895616627856,\n",
       "  3.0167362694581734,\n",
       "  2.9970295051717644,\n",
       "  2.9826997175539214,\n",
       "  2.9753367261457475,\n",
       "  3.187771584959534,\n",
       "  3.0420683893338962,\n",
       "  2.7563843433728037,\n",
       "  3.0386416661279347,\n",
       "  2.9505734784000586,\n",
       "  2.962233496036375,\n",
       "  3.0019412349259813,\n",
       "  2.9873960590924225,\n",
       "  3.0976269808802415,\n",
       "  3.0649962362665546,\n",
       "  3.18342403459307,\n",
       "  2.9795263502516613,\n",
       "  3.014815515019509,\n",
       "  3.007588105254502,\n",
       "  3.1345047065652936,\n",
       "  2.993731229688149,\n",
       "  2.879809212970846,\n",
       "  3.1193761684332593,\n",
       "  3.0836076105965486,\n",
       "  2.967965052781033,\n",
       "  3.0508032012403596,\n",
       "  3.078007639536333,\n",
       "  2.9945842233455995,\n",
       "  3.057955518969507,\n",
       "  2.9441096711735932,\n",
       "  3.005844081465633,\n",
       "  3.1907287291990403,\n",
       "  2.9938190025290172,\n",
       "  2.991158075074818,\n",
       "  2.977772938498272,\n",
       "  3.0471273448800713,\n",
       "  3.270594013315494,\n",
       "  3.011400179156409,\n",
       "  2.9008709827473855,\n",
       "  3.14479282028079,\n",
       "  3.0655473013172463,\n",
       "  2.9783482916139588,\n",
       "  2.9844788407166347,\n",
       "  2.808101282396153,\n",
       "  2.8344980900251024,\n",
       "  2.9758484907182865,\n",
       "  3.221439942374303,\n",
       "  3.020544874581481,\n",
       "  3.0021169165184975,\n",
       "  3.0229431617602307,\n",
       "  3.02358421223382,\n",
       "  3.167860529558307,\n",
       "  2.9940562160780635,\n",
       "  2.9617460939439306,\n",
       "  3.004405541251794,\n",
       "  2.9800794618880455,\n",
       "  3.1965856060023716,\n",
       "  2.947900929279296,\n",
       "  3.002646762130725,\n",
       "  2.980975329985235,\n",
       "  2.923929762515516,\n",
       "  3.0073442195991484,\n",
       "  2.9994879488358457,\n",
       "  3.0074817845102277,\n",
       "  3.000504572286285,\n",
       "  2.925943315662504,\n",
       "  3.1472053304661727,\n",
       "  2.9994879488358457,\n",
       "  2.9088395087124317,\n",
       "  2.9947649802164253,\n",
       "  2.9423730057329176,\n",
       "  3.026731840726046,\n",
       "  2.9860676912185444,\n",
       "  2.9492899282812637,\n",
       "  3.225609473261823,\n",
       "  3.2348236641535264,\n",
       "  3.1038514625741156,\n",
       "  2.972923725229301,\n",
       "  3.0023212639074575,\n",
       "  3.2395174840331995,\n",
       "  2.998187122963546,\n",
       "  2.9683486689436025,\n",
       "  2.988275684379934,\n",
       "  3.0972052510731105,\n",
       "  3.120341456894817,\n",
       "  3.023215150362072,\n",
       "  3.0012525665517407,\n",
       "  3.0653602320249282,\n",
       "  3.0230518639067108,\n",
       "  2.9633042301524455,\n",
       "  3.056533112817699,\n",
       "  3.198611232797508,\n",
       "  3.152656148750774,\n",
       "  3.163570807907081,\n",
       "  3.1316033885988004,\n",
       "  2.9918534259915655,\n",
       "  3.2114464136526175,\n",
       "  2.9497103036161567,\n",
       "  3.18164851259583,\n",
       "  2.984651072462768,\n",
       "  3.1683893430020436,\n",
       "  3.001373534293427,\n",
       "  2.996652477252958,\n",
       "  3.020626036389106,\n",
       "  3.2376391660437376,\n",
       "  3.1928301483068524,\n",
       "  3.214675409294884,\n",
       "  3.106888401594995,\n",
       "  3.0438907995052835,\n",
       "  2.992242889065288,\n",
       "  2.9025765283797273,\n",
       "  3.0282791614557745,\n",
       "  2.976795844123161,\n",
       "  3.035099987463633,\n",
       "  2.986960386259107,\n",
       "  2.933208300572615,\n",
       "  2.9750566974108557,\n",
       "  2.994211165630781,\n",
       "  2.9721184866755275,\n",
       "  3.0165546489537185,\n",
       "  2.8799091541255493,\n",
       "  2.92972924142964,\n",
       "  3.0129905791644944,\n",
       "  2.9954577580233144,\n",
       "  3.016450381863618,\n",
       "  2.994427249943465,\n",
       "  2.996991002572831,\n",
       "  2.9270542399895474,\n",
       "  2.9982759801156806,\n",
       "  3.0060777026583363,\n",
       "  2.9958652527876906,\n",
       "  3.0093141336974116,\n",
       "  2.9880798002777444,\n",
       "  3.022667956012734,\n",
       "  2.917294977050074,\n",
       "  3.0069635053620543,\n",
       "  3.023043112793663,\n",
       "  3.0237648850009515,\n",
       "  2.961035504653861,\n",
       "  2.971077854240902,\n",
       "  3.0896789070752453,\n",
       "  3.0525456611637956,\n",
       "  2.9835391695288815,\n",
       "  2.944789058761265,\n",
       "  2.978778609498702,\n",
       "  3.0946289100552105,\n",
       "  3.1416867991555266,\n",
       "  3.003316747401201,\n",
       "  3.0223326671185715,\n",
       "  2.9312024101174146,\n",
       "  2.9849598716314105,\n",
       "  2.9648589100819063,\n",
       "  3.026704834665283,\n",
       "  3.0175448071620643,\n",
       "  3.056366811186589,\n",
       "  2.939048304081121,\n",
       "  3.0172640161970916,\n",
       "  2.8058773315566943,\n",
       "  3.0407697801649736,\n",
       "  2.950571566516572,\n",
       "  2.9756968404401576,\n",
       "  2.8491145842477996,\n",
       "  3.022200266330458,\n",
       "  2.979349514320703,\n",
       "  2.9149565672278968,\n",
       "  2.899809084418703,\n",
       "  3.044409286615058,\n",
       "  3.0568706781462742,\n",
       "  3.013595473237735,\n",
       "  3.00852745286615,\n",
       "  2.8426940296924066,\n",
       "  3.2422111336438397,\n",
       "  2.9937208055299567,\n",
       "  2.981935532350146,\n",
       "  3.0161407645260434,\n",
       "  2.9977455118748377,\n",
       "  3.0188449717082757,\n",
       "  2.9839000839186087,\n",
       "  3.2703256410492356],\n",
       " array([[[ 3.42538313e-02, -1.74887644e-01, -7.49227307e-02,\n",
       "          -3.04579132e-02,  1.54770662e-05],\n",
       "         [-7.85459523e-03,  4.48613540e-02, -2.91829124e-01,\n",
       "           9.05495649e-02, -8.48859574e-02],\n",
       "         [ 1.33084629e-01, -6.89692960e-02, -4.53860541e-02,\n",
       "           1.92591004e-01,  1.84412660e-02],\n",
       "         ...,\n",
       "         [ 4.87534142e-02, -2.62484719e-02, -2.22956749e-01,\n",
       "           1.90133416e-01,  1.49330421e-01],\n",
       "         [ 1.79182238e-01,  3.60537578e-02, -3.57974653e-02,\n",
       "           2.23119998e-01,  7.84381738e-02],\n",
       "         [ 2.37613922e-03, -1.88936180e-02, -2.42690562e-01,\n",
       "           1.32836543e-01,  2.87048270e-02]],\n",
       " \n",
       "        [[ 1.42352849e-01, -3.60655510e-02, -1.27188492e-01,\n",
       "          -2.39053425e-01,  6.27584142e-02],\n",
       "         [-1.83821074e-01, -5.22798076e-02, -4.67885362e-02,\n",
       "          -1.50307158e-01,  4.55301476e-02],\n",
       "         [-9.60063250e-02, -7.45472332e-02,  3.56589085e-02,\n",
       "          -4.10862190e-02,  3.67047735e-02],\n",
       "         ...,\n",
       "         [ 1.40517590e-01,  3.85779661e-02, -1.98909464e-03,\n",
       "          -4.59455468e-02,  6.09266446e-02],\n",
       "         [ 1.07433286e-01, -3.36764687e-02, -6.41870446e-02,\n",
       "          -1.02007947e-01,  4.27539008e-03],\n",
       "         [-9.35469648e-02, -1.11502144e-01,  5.89762057e-02,\n",
       "          -5.91343918e-02, -3.10950518e-03]],\n",
       " \n",
       "        [[-4.63020326e-01, -5.32343199e-01,  1.32211335e-01,\n",
       "           6.62702179e-01,  8.11047530e-02],\n",
       "         [-9.25760188e-02, -3.58402591e-01,  3.81644132e-01,\n",
       "           1.40309530e-01,  5.80703011e-01],\n",
       "         [-4.52548315e-01, -5.78847465e-01, -2.70107368e-01,\n",
       "           4.27266328e-01,  5.55245070e-01],\n",
       "         ...,\n",
       "         [-3.41809897e-01, -5.29848548e-01,  3.76087614e-01,\n",
       "           1.72743305e-01,  5.53436599e-01],\n",
       "         [-2.54141040e-01, -4.20879417e-01,  2.16320928e-01,\n",
       "           4.34028067e-01,  3.24414082e-01],\n",
       "         [-5.61856730e-01, -6.19670115e-01,  2.52881804e-03,\n",
       "           5.98615129e-01,  6.74414239e-01]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-6.59192074e-02,  5.14949292e-02,  7.04365772e-03,\n",
       "           1.62874068e-02,  6.77240735e-02],\n",
       "         [-8.23609296e-02,  4.54346379e-02, -2.81150470e-02,\n",
       "          -2.03324360e-01, -1.38843184e-01],\n",
       "         [-3.79171179e-02, -1.04744938e-01, -6.72226452e-02,\n",
       "          -1.48312231e-02, -5.34167894e-02],\n",
       "         ...,\n",
       "         [ 2.07618468e-03,  2.93835234e-02,  4.16988806e-04,\n",
       "           1.39537684e-01, -6.23403768e-02],\n",
       "         [-1.96549670e-01, -1.14624240e-01,  1.67005646e-02,\n",
       "          -4.77949731e-02,  1.60891327e-02],\n",
       "         [-1.28738100e-01, -1.67502091e-02, -1.05023526e-02,\n",
       "           1.33699737e-01, -3.21582595e-02]],\n",
       " \n",
       "        [[-3.53073060e-02, -9.50296787e-02, -7.09433021e-03,\n",
       "           2.27015552e-01,  4.55339268e-02],\n",
       "         [-1.19622514e-01, -1.50170250e-01, -2.96020242e-01,\n",
       "           4.35601565e-01, -2.22670464e-01],\n",
       "         [-1.15041053e-01,  5.22639087e-02, -8.35477220e-02,\n",
       "           2.39218821e-01,  4.70997237e-02],\n",
       "         ...,\n",
       "         [ 3.02037664e-02, -1.64544602e-01,  1.09647413e-02,\n",
       "           1.55106008e-01, -5.31837161e-02],\n",
       "         [-4.82416092e-02, -6.48070895e-02, -1.13648591e-01,\n",
       "           3.95856738e-01,  1.06007953e-01],\n",
       "         [-9.81457993e-02,  1.02521444e-02, -1.55921074e-03,\n",
       "           3.10818501e-01, -9.88188827e-02]],\n",
       " \n",
       "        [[-5.83968760e-02, -9.17176233e-02,  1.25475759e-01,\n",
       "          -5.16423936e-02, -8.47214122e-02],\n",
       "         [-1.11312578e-01, -4.28684887e-02,  2.56229393e-01,\n",
       "          -1.13608956e-01, -1.41228786e-01],\n",
       "         [-1.08521189e-01, -5.37159843e-02,  3.91381313e-02,\n",
       "          -7.31626787e-02, -1.23351571e-01],\n",
       "         ...,\n",
       "         [-6.08860601e-02, -4.03046855e-03,  1.30939991e-01,\n",
       "          -1.18267970e-01, -6.21702951e-02],\n",
       "         [-9.41429560e-02, -4.02642829e-02,  1.00003315e-01,\n",
       "          -1.28155216e-01,  5.41380134e-02],\n",
       "         [-5.58660163e-02, -5.94912371e-02,  3.04574383e-01,\n",
       "          -7.95354318e-03, -1.06479419e-01]]]),\n",
       " array([[-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954]]),\n",
       " array([[-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954],\n",
       "        [-0.02131355, -0.18977692,  0.56780009,  0.05318991, -0.40989954]])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_rbm(training=training, validation=validation, trStats=trStats, vlStats=vlStats, \n",
    "             K=5, F=8, epochs=30, gradientLearningRate=0.001, gradientLearningRate_v = 0.0001/10,\n",
    "             gradientLearningRate_h = 0.0001/10, minibatch_size=10, alpha=0.9, \n",
    "             stopping=True, momentum=True, learning_rate_type='time', learning_rate_k=0.5, \n",
    "             learning_rate_drop=0.5, learning_rate_epochs_drop=10.0, _lambda = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### EPOCH 1 ###\n",
      "Training loss = 1.209228\n",
      "Validation loss = 1.233880\n",
      "### EPOCH 2 ###\n",
      "Training loss = 1.208409\n",
      "Validation loss = 1.233206\n",
      "### EPOCH 3 ###\n",
      "Training loss = 1.207596\n",
      "Validation loss = 1.231465\n",
      "### EPOCH 4 ###\n",
      "Training loss = 1.206502\n",
      "Validation loss = 1.231180\n",
      "### EPOCH 5 ###\n",
      "Training loss = 1.205642\n",
      "Validation loss = 1.231739\n",
      "### EPOCH 6 ###\n",
      "Training loss = 1.204354\n",
      "Validation loss = 1.229096\n",
      "### EPOCH 7 ###\n",
      "Training loss = 1.202707\n",
      "Validation loss = 1.227173\n",
      "### EPOCH 8 ###\n",
      "Training loss = 1.200873\n",
      "Validation loss = 1.225475\n",
      "### EPOCH 9 ###\n",
      "Training loss = 1.198285\n",
      "Validation loss = 1.223888\n",
      "### EPOCH 10 ###\n",
      "Training loss = 1.195312\n",
      "Validation loss = 1.222688\n",
      "### EPOCH 11 ###\n",
      "Training loss = 1.192032\n",
      "Validation loss = 1.219930\n",
      "### EPOCH 12 ###\n",
      "Training loss = 1.189056\n",
      "Validation loss = 1.216324\n",
      "### EPOCH 13 ###\n",
      "Training loss = 1.186806\n",
      "Validation loss = 1.213654\n",
      "### EPOCH 14 ###\n",
      "Training loss = 1.184304\n",
      "Validation loss = 1.212609\n",
      "### EPOCH 15 ###\n",
      "Training loss = 1.181179\n",
      "Validation loss = 1.212834\n",
      "### EPOCH 16 ###\n",
      "Training loss = 1.178905\n",
      "Validation loss = 1.207223\n",
      "### EPOCH 17 ###\n",
      "Training loss = 1.177069\n",
      "Validation loss = 1.207585\n",
      "### EPOCH 18 ###\n",
      "Training loss = 1.176345\n",
      "Validation loss = 1.207228\n",
      "### EPOCH 19 ###\n",
      "Training loss = 1.175732\n",
      "Validation loss = 1.206303\n",
      "### EPOCH 20 ###\n",
      "Training loss = 1.174323\n",
      "Validation loss = 1.206716\n",
      "### EPOCH 21 ###\n",
      "Training loss = 1.173512\n",
      "Validation loss = 1.206008\n",
      "### EPOCH 22 ###\n",
      "Training loss = 1.172620\n",
      "Validation loss = 1.205327\n",
      "### EPOCH 23 ###\n",
      "Training loss = 1.173416\n",
      "Validation loss = 1.204383\n",
      "### EPOCH 24 ###\n",
      "Training loss = 1.172552\n",
      "Validation loss = 1.206148\n",
      "### EPOCH 25 ###\n",
      "Training loss = 1.172723\n",
      "Validation loss = 1.205457\n",
      "### EPOCH 26 ###\n",
      "Training loss = 1.174192\n",
      "Validation loss = 1.206031\n",
      "### EPOCH 27 ###\n",
      "Training loss = 1.173268\n",
      "Validation loss = 1.202946\n",
      "### EPOCH 28 ###\n",
      "Training loss = 1.173180\n",
      "Validation loss = 1.207167\n",
      "### EPOCH 29 ###\n",
      "Training loss = 1.175398\n",
      "Validation loss = 1.207339\n",
      "### EPOCH 30 ###\n",
      "Training loss = 1.175788\n",
      "Validation loss = 1.206571\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best training loss = 1.172552\n",
      "Best validation loss = 1.202946\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (485,) (97,5) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-d23c175d236d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mhid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mpredictedRatings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredictForUser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhid\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0muser\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrStats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"u_users\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SpateggiChikenChoope+v3.txt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictedRatings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-d23c175d236d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mhid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mpredictedRatings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredictForUser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhid\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0muser\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrStats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"u_users\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SpateggiChikenChoope+v3.txt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictedRatings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\ESD\\Networked Life\\Project\\01.104 Test\\Scripts\\rbm.py\u001b[0m in \u001b[0;36mpredictForUser\u001b[1;34m(user, W, training, vis_bias, hid_bias, predictType)\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;31m### TO IMPLEMENT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[1;31m# given a user ID, predicts all movie ratings for the user\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpredictMovieForUser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmovie\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvis_bias\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhid_bias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictType\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpredictType\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmovie\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetUsefulStats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"u_movies\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\OneDrive\\ESD\\Networked Life\\Project\\01.104 Test\\Scripts\\rbm.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;31m### TO IMPLEMENT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[1;31m# given a user ID, predicts all movie ratings for the user\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpredictMovieForUser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmovie\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvis_bias\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhid_bias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictType\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpredictType\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmovie\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetUsefulStats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"u_movies\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\OneDrive\\ESD\\Networked Life\\Project\\01.104 Test\\Scripts\\rbm.py\u001b[0m in \u001b[0;36mpredictMovieForUser\u001b[1;34m(q, user, W, training, vis_bias, hid_bias, predictType)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[0mratingsForUser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetRatingsForUser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mratingsForUser\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m     \u001b[0mratingDistribution\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetPredictedDistribution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mratingsForUser\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvis_bias\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhid_bias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpredictType\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"max\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpredictRatingMax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mratingDistribution\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\ESD\\Networked Life\\Project\\01.104 Test\\Scripts\\rbm.py\u001b[0m in \u001b[0;36mgetPredictedDistribution\u001b[1;34m(v, w, wq, vis_bias, hid_bias)\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;31m# ret is a vector of size 5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[0mposHiddenProb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvisibleToHiddenVec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhid_bias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m     \u001b[0msampledHidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposHiddenProb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m     \u001b[0mwq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mwq\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[0mnegData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhiddenToVisible\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msampledHidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvis_bias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\ESD\\Networked Life\\Project\\01.104 Test\\Scripts\\rbm.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(p)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;31m# parameter p_i to obtain ret_i\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[0msamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgetPredictedDistribution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvis_bias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhid_bias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (485,) (97,5) "
     ]
    }
   ],
   "source": [
    "## Final parameters:\n",
    "alpha = 0.9\n",
    "_lambda = 0.1 #tuned\n",
    "gradientLearningRate = 0.001 #tuned\n",
    "minibatch_size = 10\n",
    "F = 8 \n",
    "\n",
    "W = main_rbm(training=training, validation=validation, trStats=trStats, vlStats=vlStats, \n",
    "             K=5, F=best_F, epochs=30, gradientLearningRate=best_lr, gradientLearningRate_v = 0.0001/best_batch,\n",
    "             gradientLearningRate_h = 0.0001/best_batch, minibatch_size=best_batch, alpha=best_momentum, \n",
    "             stopping=True, momentum=True, learning_rate_type='time', learning_rate_k=0.5, \n",
    "             learning_rate_drop=0.5, learning_rate_epochs_drop=10.0, _lambda = best_reg)\n",
    "\n",
    "vis = W[3]\n",
    "hid = W[4]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictedRatings = np.array([predictForUser(user, W[2], training,vis,hid) for user in trStats[\"u_users\"]])\n",
    "np.savetxt(\"SpateggiChikenChoope+v3.txt\", predictedRatings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictForUser(user, W, training,vis_bias,hid_bias, predictType=\"exp\"):\n",
    "    ### TO IMPLEMENT\n",
    "    # given a user ID, predicts all movie ratings for the user\n",
    "    return [predictMovieForUser(movie, user, W, training,vis_bias,hid_bias, predictType=predictType) for movie in lib.getUsefulStats(training)[\"u_movies\"]]\n",
    "\n",
    "def predictMovieForUser(q, user, W, training,vis_bias,hid_bias, predictType=\"exp\"):\n",
    "    # movie is movie idx\n",
    "    # user is user ID\n",
    "    # type can be \"max\" or \"exp\"\n",
    "    ratingsForUser = lib.getRatingsForUser(user, training)\n",
    "    v = rbm.getV(ratingsForUser)\n",
    "    ratingDistribution = rbm.getPredictedDistribution(v, W[ratingsForUser[:, 0], :, :], W[q, :, :],vis_bias,hid_bias[q,:])\n",
    "    if predictType == \"max\":\n",
    "        return rbm.predictRatingMax(ratingDistribution)\n",
    "    elif predictType == \"mean\":\n",
    "        return rbm.predictRatingMean(ratingDistribution)\n",
    "    else:\n",
    "        return rbm.predictRatingExp(ratingDistribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsForUser1 = lib.getRatingsForUser(0, training)\n",
    "ratingsForUser1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count%10 == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictForUser1(user, W, training,vis_bias,hid_bias, predictType=\"exp\"):\n",
    "    ### TO IMPLEMENT\n",
    "    # given a user ID, predicts all movie ratings for the user\n",
    "    return [predictMovieForUser1(movie, user, W, training,vis_bias,hid_bias, predictType=predictType) for movie in lib.getUsefulStats(training)[\"u_movies\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedRatings = np.array([predictForUser1(user, W[2], training,vis,hid) for user in trStats[\"u_users\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
